{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.各类型的缺失值处理\n",
    " * 处理思路：1. 删除含有缺失值的样本；2.替换/插补\n",
    " * np.nan类型\n",
    "     判断数据中是否存在NaN: pd.isnull(df)； pd.notnull(df)  配合any()，all()逻辑运算函数使用\n",
    "     处理方式：1.删除存在缺失值 dropna(axis='rows')\n",
    "             2.替换缺失值 fillna(value, inplace=True)  value为替换值，inplace，默认True,会删除原数据，False则不会修改原数据，二是生成新的dataframe.\n",
    " * 不是NaN类型,但有缺省标记\n",
    "     处理方式：1.将缺省标记替换成NaN, data.replace(to_replace=\"?\",value=np.nan)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.数据离散化\n",
    "   * 什么是数据离散化：连续属性的离散化是将连续属性的值域上，将值域划分为若干个离散区间，最后用不同的符号或证书值代表落在每个子区间中的属性值。\n",
    "   * 为什么要离散化：数据离散化技术可以用来减少给定连续属性值的个数。离散化方法经常作为数据挖掘的工具。称为one-hot编码或哑变量。\n",
    "   * 如何实现数据的离散化：\n",
    "       1.分组：自动分组(pd.qcut(data,bins))与自动分组(pd.cut(data,[...]))  返回series\n",
    "       2.将分组好的结果转换成one-hot编码 （pd.get_dummies(sr, prfix=)）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No1:165      (163.667, 178.0]\n",
      "No2:174      (163.667, 178.0]\n",
      "No3:160    (158.999, 163.667]\n",
      "No4:180        (178.0, 192.0]\n",
      "No5:159    (158.999, 163.667]\n",
      "No6:163    (158.999, 163.667]\n",
      "No7:192        (178.0, 192.0]\n",
      "No8:184        (178.0, 192.0]\n",
      "dtype: category\n",
      "Categories (3, interval[float64]): [(158.999, 163.667] < (163.667, 178.0] < (178.0, 192.0]]\n",
      "         height_(158.999, 163.667]  height_(163.667, 178.0]  \\\n",
      "No1:165                          0                        1   \n",
      "No2:174                          0                        1   \n",
      "No3:160                          1                        0   \n",
      "No4:180                          0                        0   \n",
      "No5:159                          1                        0   \n",
      "No6:163                          1                        0   \n",
      "No7:192                          0                        0   \n",
      "No8:184                          0                        0   \n",
      "\n",
      "         height_(178.0, 192.0]  \n",
      "No1:165                      0  \n",
      "No2:174                      0  \n",
      "No3:160                      0  \n",
      "No4:180                      1  \n",
      "No5:159                      0  \n",
      "No6:163                      0  \n",
      "No7:192                      1  \n",
      "No8:184                      1  \n",
      "(178.0, 192.0]        3\n",
      "(158.999, 163.667]    3\n",
      "(163.667, 178.0]      2\n",
      "dtype: int64\n",
      "--------------------\n",
      "No1:165    (150, 165]\n",
      "No2:174    (165, 180]\n",
      "No3:160    (150, 165]\n",
      "No4:180    (165, 180]\n",
      "No5:159    (150, 165]\n",
      "No6:163    (150, 165]\n",
      "No7:192    (180, 195]\n",
      "No8:184    (180, 195]\n",
      "dtype: category\n",
      "Categories (3, interval[int64]): [(150, 165] < (165, 180] < (180, 195]]\n",
      "         身高_(150, 165]  身高_(165, 180]  身高_(180, 195]\n",
      "No1:165              1              0              0\n",
      "No2:174              0              1              0\n",
      "No3:160              1              0              0\n",
      "No4:180              0              1              0\n",
      "No5:159              1              0              0\n",
      "No6:163              1              0              0\n",
      "No7:192              0              0              1\n",
      "No8:184              0              0              1\n",
      "(150, 165]    4\n",
      "(180, 195]    2\n",
      "(165, 180]    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 准备数据\n",
    "data=pd.Series([165,174,160,180,159,163,192,184],index=['No1:165','No2:174','No3:160','No4:180','No5:159','No6:163','No7:192','No8:184'])\n",
    "\n",
    "# 自动分组\n",
    "sr = pd.qcut(data, 3)\n",
    "print(sr)\n",
    "# 转换成one-hot编码\n",
    "print(pd.get_dummies(sr, prefix=\"height\"))\n",
    "\n",
    "# 查看分组情况\n",
    "print(sr.value_counts())\n",
    "print(\"--------------------\")\n",
    "# 自定义分组\n",
    "bins = [150,165,180,195]\n",
    "sr = pd.cut(data, bins)\n",
    "print(sr)\n",
    "# 转换成one-hot编码\n",
    "print(pd.get_dummies(sr, prefix=\"身高\"))\n",
    "# 查看分组情况\n",
    "print(sr.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.合并\n",
    "* numpy中如何处理:\n",
    "    np.concatnate((a,b),axis=)\n",
    "   * 水平拼接：\n",
    "     np.hstack()\n",
    "   * 垂直拼接\n",
    "     np.vstack()\n",
    "* pandas中如何处理：\n",
    "    * 按方向拼接\n",
    "        pd.concat([data1,data2],axis=0)\n",
    "    * 按索引拼接\n",
    "        pd.merge(left,right, how=\"inner\", on=[索引])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.交叉表与透视表（探索两个变量的关系）\n",
    "* 交叉表 : 交叉表用于计算一列数据对于另一列数据的分组个数（寻找两个列之间的关系）\n",
    "    pd.crosstab(value1, value2)\n",
    "* 透视表\n",
    "    DataFrame.pivot_table([], index=[])\n",
    "    \n",
    "### 分组与聚合\n",
    "* 分组\n",
    "    DataFrame.groupby(key, as_index=False).聚合函数（）\n",
    "    key:分组的列数据，可以多个\n",
    "    \n",
    "    sr.groupby(sr).聚合函数（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color   object  price1  price2\n",
      "0  white      pen    5.56    4.75\n",
      "1    red   pencil    4.20    4.12\n",
      "2  green   pencil    1.30    1.60\n",
      "3    red  ashtray    0.56    0.75\n",
      "4  green      pen    2.75    3.15\n",
      "------------\n",
      "   color  price1\n",
      "0  green   2.025\n",
      "1    red   2.380\n",
      "2  white   5.560\n",
      "-----------\n",
      "color\n",
      "green    2.025\n",
      "red      2.380\n",
      "white    5.560\n",
      "Name: price1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "col = pd.DataFrame({'color':['white','red','green','red','green'],\n",
    "                    'object':['pen','pencil','pencil','ashtray','pen'],\n",
    "                    'price1':[5.56,4.20,1.30,0.56,2.75],\n",
    "                    'price2':[4.75,4.12,1.60,0.75,3.15]})\n",
    "print(col)\n",
    "print(\"------------\")\n",
    "print(col.groupby(['color'], as_index=False)['price1'].mean())\n",
    "\n",
    "print(\"-----------\")\n",
    "print(col['price1'].groupby(col['color']).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
